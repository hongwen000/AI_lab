{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from typing import Callable\n",
    "from typing import Any\n",
    "from typing import Dict, Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(filen: str) -> List[List]:\n",
    "    '''\n",
    "    读取文件内容\n",
    "    由于首先需要获取文章数量和单词向量长度，才能计算TF矩阵\n",
    "    因此要对文本内容进行两次遍历，为了避免两次读取磁盘文件，故先将文本内容保存到内存中的一个list\n",
    "    '''\n",
    "    fdata = []\n",
    "    with open(filen) as fd:\n",
    "        reader = csv.reader(fd, delimiter=' ')\n",
    "        fdata = [list(row) for row in reader]\n",
    "    return fdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTFIDF(fdata: List[List]) -> np.array:\n",
    "    '''\n",
    "    获取TF-IDF矩阵\n",
    "    '''\n",
    "    #首先获取文章数和单词向量\n",
    "    #使用OrderedDict按单词出现的顺序生成单词列表\n",
    "    #相比于使用list，好处在于每次判断word是否已经加入单词向量是log(n)复杂度\n",
    "    word_dict = OrderedDict() \n",
    "    #文章数\n",
    "    D = 0\n",
    "    for row in fdata:\n",
    "        D += 1\n",
    "        for word in row:\n",
    "            if not word in word_dict:\n",
    "                word_dict[word] = 1\n",
    "            else:\n",
    "                word_dict[word] += 1\n",
    "    #word_vec是单词向量\n",
    "    word_vec = word_dict.keys()\n",
    "    #word_order的键值是当前单词的序号，在生成TF矩阵时会用到\n",
    "    word_order = dict(zip(word_vec,range(len(word_vec))))\n",
    "    #生成TF矩阵\n",
    "    TF = np.zeros((D,len(word_dict)))\n",
    "    for i,row in enumerate(fdata):\n",
    "        for word in row:\n",
    "            TF[i][word_order[word]] += 1\n",
    "        #每个文章中单词出现次数归一化\n",
    "        TF[i] /= len(fdata[i])\n",
    "    #生成IDF矩阵\n",
    "    IDF = np.log2(D / (1 + np.array(list(word_dict.values()))))\n",
    "    #生成TF-IDF矩阵\n",
    "    TF_IDF = np.multiply(TF, IDF)\n",
    "    return TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01775527000427246\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TF_IDF\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DisN(vec1: np.array, vec2: np.array, N: Any) -> float:\n",
    "    '''\n",
    "    计算N-norm\n",
    "    '''\n",
    "    if(N < 1):\n",
    "        raise ValueError(\"norm should be a positive integer or np.inf\")\n",
    "    if np.isinf(N):\n",
    "        return np.max(np.fabs(vec1 - vec2))\n",
    "    else:\n",
    "        return np.power(np.sum(np.power(vec1 - vec2, N)), 1.0/N)\n",
    "\n",
    "#Dis2 = lambda v1, v2: DisN(v1, v2, 2)\n",
    "Dis2 = lambda v1, v2: np.linalg.norm(v1 - v2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DisInvNormAvg(distances: np.array, Y: np.array) -> np.array:\n",
    "    '''\n",
    "    将距离倒数归一化，返回均值\n",
    "    '''\n",
    "    for idx, dis in enumerate(distances):\n",
    "        if dis == 0:\n",
    "            return Y[idx]\n",
    "    distances = np.array(1.0) / distances\n",
    "    s = np.sum(distances)\n",
    "    distances = distances / s\n",
    "    #print(type(distances), \" \", type(Y))\n",
    "    #print(np.diag(distances))\n",
    "    #print(Y)\n",
    "    tmp = np.diag(distances) @ Y\n",
    "    if len(tmp.shape) is 1:\n",
    "        return tmp\n",
    "    else:\n",
    "        return np.sum(tmp,  axis = (0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(trainSet: Tuple[np.array, np.array],\n",
    "        testVec: np.array,\n",
    "        DisFunc: Callable[[np.array, np.array], float],\n",
    "        K: int,\n",
    "        WeightFunc: Callable[[np.array, np.array], float]) -> np.array: \n",
    "    '''\n",
    "    一个通用的KNN接口\n",
    "    trainSet: 二元元组，第一个元素是训练集的X，第二个是Y\n",
    "    testVec: 待预测向量\n",
    "    DisFunc: 距离函数\n",
    "    K: K值\n",
    "    WeightFunc: 依据第一个参数list<距离>,对第二个参数list<Y值>进行加权，返回预测值\n",
    "    '''\n",
    "    #对于多个要预测的值，逐一预测\n",
    "    if len(testVec.shape) > 1:\n",
    "        return [KNN(trainSet, vec, DisFunc, K, WeightFunc) for vec in testVec]\n",
    "    else:\n",
    "        #测量待预测向量到训练集中每个向量的距离\n",
    "        #distances是一个list<tuple(index, distance)>\n",
    "        distances = list(enumerate(map(lambda trainVec: DisFunc(trainVec, testVec), trainSet[0])))\n",
    "        #依据距离从小到大排序\n",
    "        distances.sort(key=lambda t: t[1])\n",
    "        #获取最临近的K个训练样本的下标和对应的距离，输出值\n",
    "        tmp = list(zip(*distances[:K]))\n",
    "        kNearIdx = list(tmp[0])\n",
    "        kNearDis = list(tmp[1])\n",
    "        kNearY   = trainSet[1][kNearIdx, :]\n",
    "        #对输出值根据距离加权作为预测输出\n",
    "        return [WeightFunc(kNearDis, kNearY)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148.  22.   2. ...   0.  64.   0.]\n",
      " [131.   0.   0. ...  93.   0.  38.]\n",
      " [221.  18.   0. ...  66.  20.  65.]\n",
      " ...\n",
      " [115.   0.   0. ...  34.  13.  57.]\n",
      " [ 57.   0.   0. ...  14.   0.  43.]\n",
      " [119.  10.   6. ...  41.  17.  31.]]\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import re\n",
    "#trainX = np.array([[10,2],[2,3],[3,5]])\n",
    "#trainY = np.array([[1,1,1], [2,2,3], [3,3,5]])\n",
    "xfilen = 'lab1_data/X.txt'\n",
    "yfilen = 'lab1_data/Y.txt'\n",
    "xdata = readFile(xfilen)\n",
    "ydata = readFile(yfilen)\n",
    "x_set = getTFIDF(xdata)\n",
    "y_set = np.array([list(map(float, row)) for row in ydata])\n",
    "print(y_set)\n",
    "DIVIDE_RATE = 0.75\n",
    "train_D = int(np.ceil(x_set.shape[0] * DIVIDE_RATE))\n",
    "trainX = x_set[0:train_D, :]\n",
    "vaildX = x_set[train_D:, :]\n",
    "trainY = y_set[0:train_D, :]\n",
    "vaildY = y_set[train_D:, :]\n",
    "#print(trainX.shape[1])\n",
    "#trainX = x_set[:, 0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935\n",
      "         3204845 function calls (3204534 primitive calls) in 3.368 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   290785    0.932    0.000    2.964    0.000 <ipython-input-25-bb572e1be889>:13(<lambda>)\n",
      "      311    0.010    0.000    0.022    0.000 <ipython-input-26-7657f8c43bd0>:1(DisInvNormAvg)\n",
      "    312/1    0.150    0.000    3.368    3.368 <ipython-input-27-6298729cd5e4>:1(KNN)\n",
      "        1    0.009    0.009    3.368    3.368 <ipython-input-27-6298729cd5e4>:16(<listcomp>)\n",
      "   290785    0.088    0.000    3.052    0.000 <ipython-input-27-6298729cd5e4>:20(<lambda>)\n",
      "   290785    0.026    0.000    0.026    0.000 <ipython-input-27-6298729cd5e4>:22(<lambda>)\n",
      "        1    0.000    0.000    3.368    3.368 <string>:1(<module>)\n",
      "      620    0.000    0.000    0.006    0.000 _methods.py:31(_sum)\n",
      "      620    0.002    0.000    0.009    0.000 fromnumeric.py:1778(sum)\n",
      "   290785    0.075    0.000    0.116    0.000 linalg.py:110(isComplexType)\n",
      "   290785    1.071    0.000    2.032    0.000 linalg.py:2103(norm)\n",
      "   290785    0.077    0.000    0.172    0.000 numeric.py:424(asarray)\n",
      "      310    0.000    0.000    0.000    0.000 numeric.py:495(asanyarray)\n",
      "      310    0.003    0.000    0.004    0.000 twodim_base.py:197(diag)\n",
      "      310    0.000    0.000    0.000    0.000 {built-in method builtins.abs}\n",
      "        1    0.000    0.000    3.368    3.368 {built-in method builtins.exec}\n",
      "      620    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "   581570    0.087    0.000    0.087    0.000 {built-in method builtins.issubclass}\n",
      "      932    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "   291405    0.096    0.000    0.096    0.000 {built-in method numpy.core.multiarray.array}\n",
      "   290785    0.432    0.000    0.432    0.000 {built-in method numpy.core.multiarray.dot}\n",
      "      310    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.zeros}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "   290785    0.195    0.000    0.195    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "      620    0.006    0.000    0.006    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "      311    0.109    0.000    0.135    0.000 {method 'sort' of 'list' objects}\n",
      "\n",
      "\n",
      "3.3745229244232178\n"
     ]
    }
   ],
   "source": [
    "print(train_D)\n",
    "t = time()\n",
    "cProfile.run('KNN((trainX, trainY), vaildX,Dis2,2,DisInvNormAvg)')\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
