{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from typing import Callable\n",
    "from typing import Any\n",
    "from typing import Dict, Tuple, List\n",
    "import cProfile\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(filen: str) -> List[List]:\n",
    "    '''\n",
    "    读取文件内容\n",
    "    由于首先需要获取文章数量和单词向量长度，才能计算TF矩阵\n",
    "    因此要对文本内容进行两次遍历，为了避免两次读取磁盘文件，故先将文本内容保存到内存中的一个list\n",
    "    '''\n",
    "    fdata = []\n",
    "    with open(filen) as fd:\n",
    "        reader = csv.reader(fd, delimiter=' ')\n",
    "        fdata = [list(row) for row in reader]\n",
    "    return fdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTFIDF(fdata: List[List]) -> np.array:\n",
    "    '''\n",
    "    获取TF-IDF矩阵\n",
    "    '''\n",
    "    #首先获取文章数和单词向量\n",
    "    #使用OrderedDict按单词出现的顺序生成单词列表\n",
    "    #相比于使用list，好处在于每次判断word是否已经加入单词向量是log(n)复杂度\n",
    "    word_dict = OrderedDict() \n",
    "    #文章数\n",
    "    D = 0\n",
    "    for row in fdata:\n",
    "        D += 1\n",
    "        for word in row:\n",
    "            if not word in word_dict:\n",
    "                word_dict[word] = 1\n",
    "            else:\n",
    "                word_dict[word] += 1\n",
    "    #word_vec是单词向量\n",
    "    word_vec = word_dict.keys()\n",
    "    #word_order的键值是当前单词的序号，在生成TF矩阵时会用到\n",
    "    word_order = dict(zip(word_vec,range(len(word_vec))))\n",
    "    #生成TF矩阵\n",
    "    TF = np.zeros((D,len(word_dict)))\n",
    "    for i,row in enumerate(fdata):\n",
    "        for word in row:\n",
    "            TF[i][word_order[word]] += 1\n",
    "        #每个文章中单词出现次数归一化\n",
    "        TF[i] /= len(fdata[i])\n",
    "    #生成IDF矩阵\n",
    "    IDF = np.log(D / (1 + np.array(list(word_dict.values()))))\n",
    "\n",
    "    #生成TF-IDF矩阵\n",
    "    TF_IDF = np.multiply(TF, IDF)\n",
    "    return TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.20273255,  0.        ],\n",
       "       [ 0.        , -0.20273255,  0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getTFIDF([[\"b\", \"c\"], [\"a\", \"c\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "semval = readFile('lab1_data/semeval_sliced.txt')\n",
    "ret = getTFIDF(semval)\n",
    "#ret = ret.tolist()\n",
    "#rt = []\n",
    "#for row in ret:\n",
    "#    rr = []\n",
    "#    for w in row:\n",
    "#        if row != 0:\n",
    "#           rr.append(w)\n",
    "#    rt.append(rr)\n",
    "#ret = np.array(rt)\n",
    "##print(ret)\n",
    "np.savetxt(\"15323032_LiXinrui_TFIDF.txt\", ret, delimiter=\" \", fmt=\"%6f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_getTFIDF(fdata: List[List], word_dict: OrderedDict) -> np.array:\n",
    "    '''\n",
    "    获取TF-IDF矩阵，并将每个单词及出现次数存储到word_dict中\n",
    "    '''\n",
    "    #首先获取文章数和单词向量\n",
    "    #使用OrderedDict按单词出现的顺序生成单词列表\n",
    "    #相比于使用list，好处在于每次判断word是否已经加入单词向量是log(n)复杂度\n",
    "    #文章数\n",
    "    D = len(fdata)\n",
    "    if len(word_dict) is 0:\n",
    "        #训练集\n",
    "        for row in fdata:\n",
    "            for word in row:\n",
    "                if not word in word_dict:\n",
    "                    word_dict[word] = 1\n",
    "                else:\n",
    "                    word_dict[word] += 1\n",
    "        word_dict[None] = 0\n",
    "    else:\n",
    "        #验证集和测试集，丢弃未出现的单词\n",
    "        word_dict = dict(zip(word_dict.keys(), [0 for _ in word_dict.values()]))\n",
    "        for row in fdata:\n",
    "            for word in row:\n",
    "                if word in word_dict:\n",
    "                    word_dict[word] += 1\n",
    "                else:\n",
    "                    word_dict[None] += 1\n",
    "    #word_vec是单词向量\n",
    "    word_vec = word_dict.keys()\n",
    "    #word_order的键值是当前单词的序号，在生成TF矩阵时会用到\n",
    "    word_order = dict(zip(word_vec,range(len(word_vec))))\n",
    "    #生成TF矩阵\n",
    "    TF = np.zeros((D,len(word_dict)))\n",
    "    for i,row in enumerate(fdata):\n",
    "        for word in row:\n",
    "            if word in word_order:\n",
    "                TF[i][word_order[word]] += 1\n",
    "            else:\n",
    "                TF[i][word_order[None]] += 1\n",
    "        #每个文章中单词出现次数归一化\n",
    "        TF[i] /= len(fdata[i])\n",
    "    #生成IDF矩阵\n",
    "    IDF = np.log2(D / (1 + np.array(list(word_dict.values()))))\n",
    "    #生成TF-IDF矩阵\n",
    "    TF_IDF = np.multiply(TF, IDF)\n",
    "    return TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. ,  0. ,  0. ],\n",
       "       [-0.5,  0. ,  0. ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdict = OrderedDict()\n",
    "KNN_getTFIDF([['a','a'],['c','a']], wdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOneHot(fdata: List[List], word_dict: OrderedDict) -> np.array:\n",
    "    D = len(fdata)\n",
    "    if len(word_dict) is 0:\n",
    "        for row in fdata:\n",
    "            for word in row:\n",
    "                if not word in word_dict:\n",
    "                    word_dict[word] = 1\n",
    "        word_dict[None] = 0\n",
    "    else:\n",
    "        word_dict = dict(zip(word_dict.keys(), [0 for _ in word_dict.values()]))\n",
    "        for row in fdata:\n",
    "            for word in row:\n",
    "                if word in word_dict:\n",
    "                    word_dict[word] = 1\n",
    "                else:\n",
    "                    word_dict[None] = 1\n",
    "    word_vec = word_dict.keys()\n",
    "    word_order = dict(zip(word_vec,range(len(word_vec))))\n",
    "    oneHot = np.zeros((D,len(word_dict)))\n",
    "    for i,row in enumerate(fdata):\n",
    "        for word in row:\n",
    "            if word in word_order:\n",
    "                oneHot[i][word_order[word]] = 1\n",
    "            else:\n",
    "                oneHot[i][word_order[None]] = 1\n",
    "    return oneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdict = OrderedDict()\n",
    "getOneHot([['a','a'],['c','a']], wdict)\n",
    "getOneHot([['d','d']], wdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DisN(vec1: np.array, vec2: np.array, N: Any) -> float:\n",
    "    '''\n",
    "    计算N-norm\n",
    "    '''\n",
    "    if(N < 1):\n",
    "        raise ValueError(\"norm should be a positive integer or np.inf\")\n",
    "    if np.isinf(N):\n",
    "        return np.max(np.fabs(vec1 - vec2))\n",
    "    else:\n",
    "        return np.power(np.sum(np.power(vec1 - vec2, N)), 1.0/N)\n",
    "\n",
    "#Dis2 = lambda v1, v2: DisN(v1, v2, 2)\n",
    "# 一范数\n",
    "Dis1 = lambda v1, v2: np.linalg.norm(v1 - v2, 1)\n",
    "# 二范数\n",
    "Dis2 = lambda v1, v2: np.linalg.norm(v1 - v2, 2)\n",
    "# 无穷范数\n",
    "DisInf = lambda v1, v2: np.linalg.norm(v1 - v2, np.inf)\n",
    "# 余弦距离（1-余弦相关度）\n",
    "def DisCosine(v1, v2):\n",
    "    t1 = np.dot(v1,v2)\n",
    "    t2 = np.linalg.norm(v1)\n",
    "    t3 = np.linalg.norm(v2)\n",
    "    ret = 1 - t1 / (t2*t3)\n",
    "    return ret\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DisCosine([0,1],[0,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DisInvNormAvg(distances: np.array, Y: np.array) -> np.array:\n",
    "    '''\n",
    "    按照归一化的距离倒数加权求和，返回均值\n",
    "    '''\n",
    "    # 如果训练集中有向量距离和待预测向量完全一致（距离为0）\n",
    "    for idx, dis in enumerate(distances):\n",
    "        if np.isclose(dis, 0):\n",
    "            # 则直接返回该训练集向量对应的Y\n",
    "            return Y[idx]\n",
    "    # 求距离的倒数\n",
    "    distances = np.array(1.0) / distances\n",
    "    # 归一化\n",
    "    s = np.sum(distances)\n",
    "    distances = distances / s\n",
    "    # 分别作为权值乘以K个最邻近的训练集向量对应的Y\n",
    "    tmp = np.diag(distances) @ Y  \n",
    "    # 加权后Y的个分量求和\n",
    "    if len(tmp.shape) is 1:\n",
    "        return tmp\n",
    "    else:\n",
    "        return np.sum(tmp,  axis = (0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(trainSet: Tuple[np.array, np.array],\n",
    "        testVec: np.array,\n",
    "        DisFunc: Callable[[np.array, np.array], float],\n",
    "        K: int,\n",
    "        WeightFunc: Callable[[np.array, np.array], float]) -> np.array: \n",
    "    '''\n",
    "    一个通用的KNN接口\n",
    "    trainSet: 二元元组，第一个元素是训练集的X，第二个是Y\n",
    "    testVec: 待预测向量\n",
    "    DisFunc: 距离函数\n",
    "    K: K值\n",
    "    WeightFunc: 依据第一个参数list<距离>,对第二个参数list<Y值>进行加权，返回预测值\n",
    "    '''\n",
    "    #对于多个要预测的值，逐一预测\n",
    "    if len(testVec.shape) > 1:\n",
    "        return np.array([KNN(trainSet, vec, DisFunc, K, WeightFunc) for vec in testVec])\n",
    "    else:\n",
    "        #测量待预测向量到训练集中每个向量的距离\n",
    "        #distances是一个list<tuple(index, distance)>\n",
    "        distances = list(enumerate(map(lambda trainVec: DisFunc(trainVec, testVec), trainSet[0])))\n",
    "        #依据距离从小到大排序\n",
    "        distances.sort(key=lambda t: t[1])\n",
    "        #获取最临近的K个训练样本的下标和对应的距离，输出值\n",
    "        tmp = list(zip(*distances[:K]))\n",
    "        kNearIdx = list(tmp[0])\n",
    "        kNearDis = list(tmp[1])\n",
    "        kNearY   = trainSet[1][kNearIdx, :]\n",
    "        #对输出值根据距离加权作为预测输出\n",
    "        return WeightFunc(kNearDis, kNearY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestCast1():\n",
    "    trainX = np.array([[10,2],[2,3],[3,5]])\n",
    "    trainY = np.array([[1,1,1], [2,2,3], [3,3,5]])\n",
    "    vaildX = np.array([[3,3]])\n",
    "    return trainX, trainY, vaildX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2., 3.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX, trainY, vaildX = TestCast1()\n",
    "KNN((trainX, trainY), vaildX, Dis2, 1, DisInvNormAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestCast2():\n",
    "    xfilen = 'lab1_data/X.txt'\n",
    "    yfilen = 'lab1_data/Y.txt'\n",
    "    xdata = readFile(xfilen)\n",
    "    ydata = readFile(yfilen)\n",
    "    x_set = getTFIDF(xdata)\n",
    "    y_set = np.array([list(map(float, row)) for row in ydata])\n",
    "    DIVIDE_RATE = 0.75\n",
    "    train_D = int(np.ceil(x_set.shape[0] * DIVIDE_RATE))\n",
    "    trainX = x_set[0:train_D, :]\n",
    "    vaildX = x_set[train_D:, :]\n",
    "    trainY = y_set[0:train_D, :]\n",
    "    vaildY = y_set[train_D:, :]\n",
    "    return trainX, trainY, vaildX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(trainX, trainY, vaildX):\n",
    "    t = time()\n",
    "    cProfile.run('KNN((trainX, trainY), vaildX,Dis2,2,DisInvNormAvg)')\n",
    "    print(time()-t) \n",
    "#trainX, trainY, vaildX = TestCast2()\n",
    "#Test(trainX, trainY, vaildX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyReadFile(filen: str) -> Tuple[List[str], List[str]]:\n",
    "    with open(filen) as fd:\n",
    "        reader = csv.reader(fd, delimiter=',')\n",
    "        train_data = [list(row) for row in reader]\n",
    "        train_data = train_data[1:]\n",
    "        tmp = list(zip(*train_data))\n",
    "        xdata = [row.split() for row in list(tmp[0])]\n",
    "        ydata = list(tmp[1])\n",
    "        return xdata, ydata\n",
    "\n",
    "def vectorizeData(xdata, ydata, xVecFunc, yVecFunc):\n",
    "    return xVecFunc(xdata), yVecFunc(ydata)\n",
    "\n",
    "def fastHashY(s: str) -> int:\n",
    "    if s[0] is 'a': return 0\n",
    "    if s[0] is 'd': return 1\n",
    "    if s[0] is 'f': return 2\n",
    "    if s[0] is 'j': return 3\n",
    "    if s[1] is 'a': return 4\n",
    "    return 5\n",
    "\n",
    "def classifyParseY(ydata: List[str])->np.array:\n",
    "    '''\n",
    "    Convert Y data from raw string list to matrix consisted of Y vectors\n",
    "    e.g.\n",
    "    [\"anger\", \"disgust\", ..., \"surprise\"] -> \n",
    "    |1, 0, 0, 0, 0, 0|\n",
    "    |0, 1, 0, 0, 0, 0|\n",
    "    |0, 0, ...,  0, 0|\n",
    "    |0, 0, 0, 0, 1, 0|\n",
    "    |0, 0, 0, 0, 0, 1|\n",
    "    '''\n",
    "    D = len(ydata)\n",
    "    \n",
    "    #fast hash ydata from strings [\"anger\", \"disgust\", ...] to [1, 2, ...]^T\n",
    "    ydata = np.array(list(map(fastHashY, ydata))).reshape((-1,1))\n",
    "    \n",
    "    '''\n",
    "    ymat is the column-wise repeat of ydata.\n",
    "    e.g.\n",
    "    |0|      |0, 0, 0, 0, 0, 0|\n",
    "    |1|   -> |1, 1, 1, 1, 1, 1|\n",
    "    ...      |................|\n",
    "    |5|      |5, 5, 5, 5, 5, 5|\n",
    "    ydata -> ymat\n",
    "    '''\n",
    "    ymat  = np.tile(ydata, (1, 6))\n",
    "    \n",
    "    '''\n",
    "    ycmp is a matrix of which each row is [0, 1, 2, 3, 4, 5]\n",
    "    |0, 1, 2, 3, 4, 5|\n",
    "    |0, 1, 2, 3, 4, 5|\n",
    "    |................|\n",
    "    |0, 1, 2, 3, 4, 5|\n",
    "    '''\n",
    "    ycmp  = np.tile(np.array(range(6)), (D, 1))\n",
    "    return np.int_(np.equal(ymat, ycmp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_classify(trainX, trainY, vaildX, vaildY, knnFunc):\n",
    "    predictY = knnFunc(trainX, trainY, vaildX)\n",
    "    classifyY = np.zeros_like(predictY)\n",
    "    for i, row in enumerate(predictY):\n",
    "        m = 0\n",
    "        idx = 0\n",
    "        for j, v in enumerate(row):\n",
    "            if v > m:\n",
    "                m = v\n",
    "                idx = j\n",
    "        classifyY[i][idx] = 1\n",
    "        if idx is 0:\n",
    "            print(\"anger\")\n",
    "        if idx is 1:\n",
    "            print(\"disgust\")\n",
    "        if idx is 2:\n",
    "            print(\"fear\")\n",
    "        if idx is 3:\n",
    "            print(\"joy\")\n",
    "        if idx is 4:\n",
    "            print(\"sad\")\n",
    "        if idx is 5:\n",
    "            print(\"surprise\")\n",
    "\n",
    "    #print(\"Predicted Y\")\n",
    "    #print(classifyY)\n",
    "    #print(\"Correct Y\")\n",
    "    #print(vaildY)\n",
    "    ret = np.sum(np.logical_and(classifyY, vaildY)) / vaildX.shape[0]\n",
    "    print(\"Classification Accuracy: \", ret)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressReadFile(filen: str) -> Tuple[List[str], List[str]]:\n",
    "    with open(filen) as fd:\n",
    "        reader = csv.reader(fd, delimiter=',')\n",
    "        train_data = [list(row) for row in reader]\n",
    "        train_data = train_data[1:]\n",
    "        xdata = [row[0].split() for row in train_data]\n",
    "        ydata = [[row[i] for i in range(1, 7)] for row in train_data]\n",
    "        return xdata, ydata\n",
    "\n",
    "def regressParseY(ydata: List[List[str]]) -> np.array:\n",
    "    if ydata[0][0] is '?':\n",
    "        return np.zeros_like(ydata)\n",
    "    return np.float_(np.array(ydata))\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "#def pearsonr(X, Y):\n",
    "#\n",
    "#    X_bar = np.average(X)\n",
    "#    Y_bar = np.average(Y)\n",
    "#    X = np.subtract(X, X_bar)\n",
    "#    Y = np.subtract(Y, Y_bar)\n",
    "#    t1 = np.sum(np.dot(X, Y))\n",
    "#    t2 = np.sum(np.power(X,2))\n",
    "#    t3 = np.sum(np.power(Y,2))\n",
    "#\n",
    "#    ret = t1 / np.power(t2 * t3, 0.5)\n",
    "#    return ret\n",
    "def do_regress(trainX, trainY, vaildX, vaildY, knnFunc, save = False):\n",
    "    predictY = knnFunc(trainX, trainY, vaildX)\n",
    "    if save:\n",
    "        np.savetxt(\"regress.csv\", predictY, delimiter=\",\", fmt=\"%4f\")\n",
    "    r = [pearsonr(predictY[:, i], vaildY[:, i])[0] for i in range(6)]\n",
    "    average = np.average(r)\n",
    "    print(\"Correlation Coefficient: \", average)\n",
    "    return average\n",
    "    \n",
    "    \n",
    "train_filen = 'lab1_data/regression_dataset/train_set.csv'\n",
    "vaild_filen = 'lab1_data/regression_dataset/validation_set.csv'\n",
    "test_filen  = 'lab1_data/regression_dataset/test_set.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_filen = 'lab1_data/classification_dataset/train_set.csv'\n",
    "#vaild_filen = 'lab1_data/classification_dataset/validation_set.csv'\n",
    "#test_filen  = 'lab1_data/classification_dataset/test_set.csv'\n",
    "#\n",
    "#trainX_data, trainY_data = classifyReadFile(train_filen)\n",
    "#vaildX_data, vaildY_data = classifyReadFile(vaild_filen)\n",
    "#\n",
    "#ParseFuncs = {\"OneHot\": getOneHot, \"TI-IDF\": KNN_getTFIDF}\n",
    "#K_val = range(1, 20)\n",
    "#DisFuncs = {\"Dis1\": Dis1, \"Dis2\": Dis2, \"DisInf\": DisInf, \"DisCosine\": DisCosine}\n",
    "#\n",
    "#results = OrderedDict()\n",
    "#\n",
    "#for pfname, ParseFunc in ParseFuncs.items():\n",
    "#    word_dict = OrderedDict()\n",
    "#    def classifyParseX(fdata: List[List]): return ParseFunc(fdata, word_dict)\n",
    "#    trainX, trainY = vectorizeData(trainX_data, trainY_data, classifyParseX, classifyParseY)\n",
    "#    vaildX, vaildY = vectorizeData(vaildX_data, vaildY_data, classifyParseX, classifyParseY)\n",
    "#    for K in K_val:\n",
    "#        for dfname, DisFunc in DisFuncs.items():\n",
    "#            print(\"ParseFunc = {}, K = {}, DisFunc = {}\".format(pfname, K, dfname))\n",
    "#            def knnFunc(trainX, trainY, vaildX): return KNN((trainX, trainY), vaildX, DisFunc, K, DisInvNormAvg)\n",
    "#            ret = do_classify(trainX, trainY, vaildX, vaildY, knnFunc)\n",
    "#            results[(pfname, K, dfname)] = ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoTrain(train_filen, vaild_filen, ReadFileFunc, ParseYFunc, TrainFunc):\n",
    "    print(\"Start training...\")\n",
    "    t = time()\n",
    "    trainX_data, trainY_data = ReadFileFunc(train_filen)\n",
    "    vaildX_data, vaildY_data = ReadFileFunc(vaild_filen)\n",
    "    \n",
    "    ParseFuncs = {\"OneHot\": getOneHot, \"TI-IDF\": KNN_getTFIDF}\n",
    "    K_val = range(8, 14)\n",
    "    DisFuncs = {\"Dis1\": Dis1, \"Dis2\": Dis2, \"DisInf\": DisInf, \"DisCosine\": DisCosine}\n",
    "    #DisFuncs = {\"DisCosine\": DisCosine}\n",
    "    results = OrderedDict()\n",
    "    \n",
    "    for pfname, ParseFunc in ParseFuncs.items():\n",
    "        word_dict = OrderedDict()\n",
    "        def ParseXFunc(fdata: List[List]): return ParseFunc(fdata, word_dict)\n",
    "        trainX, trainY = vectorizeData(trainX_data, trainY_data, ParseXFunc, ParseYFunc)\n",
    "        vaildX, vaildY = vectorizeData(vaildX_data, vaildY_data, ParseXFunc, ParseYFunc)\n",
    "        for K in K_val:\n",
    "            for dfname, DisFunc in DisFuncs.items():\n",
    "                print(\"ParseFunc = {}, K = {}, DisFunc = {}\".format(pfname, K, dfname))\n",
    "                def knnFunc(trainX, trainY, vaildX): return KNN((trainX, trainY), vaildX, DisFunc, K, DisInvNormAvg)\n",
    "                ret = TrainFunc(trainX, trainY, vaildX, vaildY, knnFunc)\n",
    "                results[(pfname, K, dfname)] = ret\n",
    "    print(\"{} groups of argument tested, spent {}s\".format(len(ParseFuncs) * len(K_val) * len(DisFuncs), time() - t))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "ParseFunc = OneHot, K = 8, DisFunc = Dis1\n",
      "Correlation Coefficient:  0.014621701763969847\n",
      "ParseFunc = OneHot, K = 8, DisFunc = Dis2\n",
      "Correlation Coefficient:  0.010185941572604896\n",
      "ParseFunc = OneHot, K = 8, DisFunc = DisInf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/intel/intelpython3/lib/python3.6/site-packages/scipy/stats/stats.py:3003: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n",
      "/opt/intel/intelpython3/lib/python3.6/site-packages/scipy/stats/stats.py:5240: RuntimeWarning: invalid value encountered in less\n",
      "  x = np.where(x < 1.0, x, 1.0)  # if x > 1 then return 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Coefficient:  nan\n",
      "ParseFunc = OneHot, K = 8, DisFunc = DisCosine\n",
      "Correlation Coefficient:  0.14422915063073075\n",
      "ParseFunc = OneHot, K = 9, DisFunc = Dis1\n",
      "Correlation Coefficient:  0.068839190450758\n",
      "ParseFunc = OneHot, K = 9, DisFunc = Dis2\n",
      "Correlation Coefficient:  0.0677163614101088\n",
      "ParseFunc = OneHot, K = 9, DisFunc = DisInf\n",
      "Correlation Coefficient:  nan\n",
      "ParseFunc = OneHot, K = 9, DisFunc = DisCosine\n",
      "Correlation Coefficient:  0.14535638921816824\n",
      "ParseFunc = OneHot, K = 10, DisFunc = Dis1\n",
      "Correlation Coefficient:  0.019761681982115507\n",
      "ParseFunc = OneHot, K = 10, DisFunc = Dis2\n",
      "Correlation Coefficient:  0.0166336329103878\n",
      "ParseFunc = OneHot, K = 10, DisFunc = DisInf\n",
      "Correlation Coefficient:  nan\n",
      "ParseFunc = OneHot, K = 10, DisFunc = DisCosine\n",
      "Correlation Coefficient:  0.12019731582401032\n",
      "ParseFunc = OneHot, K = 11, DisFunc = Dis1\n",
      "Correlation Coefficient:  0.07275163092217607\n",
      "ParseFunc = OneHot, K = 11, DisFunc = Dis2\n",
      "Correlation Coefficient:  0.07199644776535992\n",
      "ParseFunc = OneHot, K = 11, DisFunc = DisInf\n",
      "Correlation Coefficient:  nan\n",
      "ParseFunc = OneHot, K = 11, DisFunc = DisCosine\n",
      "Correlation Coefficient:  0.12535041383007875\n",
      "ParseFunc = OneHot, K = 12, DisFunc = Dis1\n",
      "Correlation Coefficient:  0.11529531375635386\n",
      "ParseFunc = OneHot, K = 12, DisFunc = Dis2\n",
      "Correlation Coefficient:  0.11471493302581488\n",
      "ParseFunc = OneHot, K = 12, DisFunc = DisInf\n",
      "Correlation Coefficient:  nan\n",
      "ParseFunc = OneHot, K = 12, DisFunc = DisCosine\n",
      "Correlation Coefficient:  0.11716670929195938\n",
      "ParseFunc = OneHot, K = 13, DisFunc = Dis1\n",
      "Correlation Coefficient:  0.11728790113729382\n",
      "ParseFunc = OneHot, K = 13, DisFunc = Dis2\n",
      "Correlation Coefficient:  0.11530713739396554\n",
      "ParseFunc = OneHot, K = 13, DisFunc = DisInf\n",
      "Correlation Coefficient:  nan\n",
      "ParseFunc = OneHot, K = 13, DisFunc = DisCosine\n",
      "Correlation Coefficient:  0.07402992915185862\n",
      "ParseFunc = TI-IDF, K = 8, DisFunc = Dis1\n",
      "Correlation Coefficient:  0.17822872901434397\n",
      "ParseFunc = TI-IDF, K = 8, DisFunc = Dis2\n",
      "Correlation Coefficient:  0.10825907568634396\n",
      "ParseFunc = TI-IDF, K = 8, DisFunc = DisInf\n",
      "Correlation Coefficient:  -0.07193548951788842\n",
      "ParseFunc = TI-IDF, K = 8, DisFunc = DisCosine\n",
      "Correlation Coefficient:  0.3243761817506015\n",
      "ParseFunc = TI-IDF, K = 9, DisFunc = Dis1\n",
      "Correlation Coefficient:  0.18727471353307015\n",
      "ParseFunc = TI-IDF, K = 9, DisFunc = Dis2\n",
      "Correlation Coefficient:  0.006364850321251225\n",
      "ParseFunc = TI-IDF, K = 9, DisFunc = DisInf\n",
      "Correlation Coefficient:  -0.07022235438149386\n",
      "ParseFunc = TI-IDF, K = 9, DisFunc = DisCosine\n",
      "Correlation Coefficient:  0.3110749022867883\n",
      "ParseFunc = TI-IDF, K = 10, DisFunc = Dis1\n",
      "Correlation Coefficient:  0.1940584122652229\n",
      "ParseFunc = TI-IDF, K = 10, DisFunc = Dis2\n",
      "Correlation Coefficient:  0.02090894677149753\n",
      "ParseFunc = TI-IDF, K = 10, DisFunc = DisInf\n",
      "Correlation Coefficient:  0.033290633972255596\n",
      "ParseFunc = TI-IDF, K = 10, DisFunc = DisCosine\n",
      "Correlation Coefficient:  0.2795617053186809\n",
      "ParseFunc = TI-IDF, K = 11, DisFunc = Dis1\n",
      "Correlation Coefficient:  0.18618206208300947\n",
      "ParseFunc = TI-IDF, K = 11, DisFunc = Dis2\n",
      "Correlation Coefficient:  0.025998644054975525\n",
      "ParseFunc = TI-IDF, K = 11, DisFunc = DisInf\n",
      "Correlation Coefficient:  -0.03772311525175214\n",
      "ParseFunc = TI-IDF, K = 11, DisFunc = DisCosine\n",
      "Correlation Coefficient:  0.2946464336659154\n",
      "ParseFunc = TI-IDF, K = 12, DisFunc = Dis1\n",
      "Correlation Coefficient:  0.15600179278302273\n",
      "ParseFunc = TI-IDF, K = 12, DisFunc = Dis2\n",
      "Correlation Coefficient:  0.080667669173477\n",
      "ParseFunc = TI-IDF, K = 12, DisFunc = DisInf\n",
      "Correlation Coefficient:  0.015611653900144332\n",
      "ParseFunc = TI-IDF, K = 12, DisFunc = DisCosine\n",
      "Correlation Coefficient:  0.29215612729995527\n",
      "ParseFunc = TI-IDF, K = 13, DisFunc = Dis1\n",
      "Correlation Coefficient:  0.18896057300694216\n",
      "ParseFunc = TI-IDF, K = 13, DisFunc = Dis2\n",
      "Correlation Coefficient:  0.015461260253084341\n",
      "ParseFunc = TI-IDF, K = 13, DisFunc = DisInf\n",
      "Correlation Coefficient:  -0.04355139198132124\n",
      "ParseFunc = TI-IDF, K = 13, DisFunc = DisCosine\n",
      "Correlation Coefficient:  0.26733021096490167\n",
      "48 groups of argument tested, spent 9.576008796691895s\n"
     ]
    }
   ],
   "source": [
    "train_filen = 'lab1_data/regression_dataset/train_set.csv'\n",
    "vaild_filen = 'lab1_data/regression_dataset/validation_set.csv'\n",
    "test_filen  = 'lab1_data/regression_dataset/test_set.csv'\n",
    "check_filen = 'lab1_data/regression_dataset/regression_simple_test.csv'\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "regressResults = autoTrain(train_filen, check_filen, regressReadFile, regressParseY, do_regress)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "ParseFunc = OneHot, K = 8, DisFunc = Dis1\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "Classification Accuracy:  0.2\n",
      "ParseFunc = OneHot, K = 8, DisFunc = Dis2\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "Classification Accuracy:  0.2\n",
      "ParseFunc = OneHot, K = 8, DisFunc = DisInf\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "Classification Accuracy:  0.2\n",
      "ParseFunc = OneHot, K = 8, DisFunc = DisCosine\n",
      "joy\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "anger\n",
      "sad\n",
      "sad\n",
      "joy\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "sad\n",
      "surprise\n",
      "anger\n",
      "Classification Accuracy:  0.28\n",
      "ParseFunc = OneHot, K = 9, DisFunc = Dis1\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "Classification Accuracy:  0.2\n",
      "ParseFunc = OneHot, K = 9, DisFunc = Dis2\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "Classification Accuracy:  0.2\n",
      "ParseFunc = OneHot, K = 9, DisFunc = DisInf\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "Classification Accuracy:  0.2\n",
      "ParseFunc = OneHot, K = 9, DisFunc = DisCosine\n",
      "joy\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "sad\n",
      "sad\n",
      "joy\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "sad\n",
      "surprise\n",
      "anger\n",
      "Classification Accuracy:  0.24\n",
      "ParseFunc = OneHot, K = 10, DisFunc = Dis1\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "Classification Accuracy:  0.24\n",
      "ParseFunc = OneHot, K = 10, DisFunc = Dis2\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "Classification Accuracy:  0.24\n",
      "ParseFunc = OneHot, K = 10, DisFunc = DisInf\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "Classification Accuracy:  0.2\n",
      "ParseFunc = OneHot, K = 10, DisFunc = DisCosine\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "anger\n",
      "sad\n",
      "sad\n",
      "joy\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "sad\n",
      "surprise\n",
      "anger\n",
      "Classification Accuracy:  0.24\n",
      "ParseFunc = OneHot, K = 11, DisFunc = Dis1\n",
      "joy\n",
      "fear\n",
      "sad\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "Classification Accuracy:  0.28\n",
      "ParseFunc = OneHot, K = 11, DisFunc = Dis2\n",
      "joy\n",
      "fear\n",
      "sad\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "Classification Accuracy:  0.28\n",
      "ParseFunc = OneHot, K = 11, DisFunc = DisInf\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "Classification Accuracy:  0.2\n",
      "ParseFunc = OneHot, K = 11, DisFunc = DisCosine\n",
      "joy\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "anger\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "sad\n",
      "surprise\n",
      "anger\n",
      "Classification Accuracy:  0.24\n",
      "ParseFunc = OneHot, K = 12, DisFunc = Dis1\n",
      "joy\n",
      "fear\n",
      "sad\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "Classification Accuracy:  0.24\n",
      "ParseFunc = OneHot, K = 12, DisFunc = Dis2\n",
      "joy\n",
      "fear\n",
      "sad\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "Classification Accuracy:  0.24\n",
      "ParseFunc = OneHot, K = 12, DisFunc = DisInf\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "Classification Accuracy:  0.2\n",
      "ParseFunc = OneHot, K = 12, DisFunc = DisCosine\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "anger\n",
      "sad\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "sad\n",
      "surprise\n",
      "anger\n",
      "Classification Accuracy:  0.24\n",
      "ParseFunc = OneHot, K = 13, DisFunc = Dis1\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "Classification Accuracy:  0.24\n",
      "ParseFunc = OneHot, K = 13, DisFunc = Dis2\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "Classification Accuracy:  0.24\n",
      "ParseFunc = OneHot, K = 13, DisFunc = DisInf\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "Classification Accuracy:  0.2\n",
      "ParseFunc = OneHot, K = 13, DisFunc = DisCosine\n",
      "joy\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "anger\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "surprise\n",
      "fear\n",
      "sad\n",
      "fear\n",
      "anger\n",
      "Classification Accuracy:  0.24\n",
      "ParseFunc = TI-IDF, K = 8, DisFunc = Dis1\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "joy\n",
      "anger\n",
      "surprise\n",
      "fear\n",
      "sad\n",
      "surprise\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "fear\n",
      "sad\n",
      "fear\n",
      "joy\n",
      "Classification Accuracy:  0.24\n",
      "ParseFunc = TI-IDF, K = 8, DisFunc = Dis2\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "anger\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "Classification Accuracy:  0.24\n",
      "ParseFunc = TI-IDF, K = 8, DisFunc = DisInf\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "Classification Accuracy:  0.24\n",
      "ParseFunc = TI-IDF, K = 8, DisFunc = DisCosine\n",
      "sad\n",
      "joy\n",
      "sad\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "sad\n",
      "sad\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "joy\n",
      "joy\n",
      "anger\n",
      "sad\n",
      "sad\n",
      "joy\n",
      "joy\n",
      "sad\n",
      "sad\n",
      "surprise\n",
      "fear\n",
      "sad\n",
      "fear\n",
      "joy\n",
      "Classification Accuracy:  0.4\n",
      "ParseFunc = TI-IDF, K = 9, DisFunc = Dis1\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "joy\n",
      "anger\n",
      "surprise\n",
      "fear\n",
      "fear\n",
      "sad\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "Classification Accuracy:  0.32\n",
      "ParseFunc = TI-IDF, K = 9, DisFunc = Dis2\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "Classification Accuracy:  0.2\n",
      "ParseFunc = TI-IDF, K = 9, DisFunc = DisInf\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "Classification Accuracy:  0.24\n",
      "ParseFunc = TI-IDF, K = 9, DisFunc = DisCosine\n",
      "sad\n",
      "joy\n",
      "sad\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "joy\n",
      "joy\n",
      "anger\n",
      "sad\n",
      "sad\n",
      "joy\n",
      "joy\n",
      "sad\n",
      "sad\n",
      "surprise\n",
      "fear\n",
      "sad\n",
      "fear\n",
      "joy\n",
      "Classification Accuracy:  0.36\n",
      "ParseFunc = TI-IDF, K = 10, DisFunc = Dis1\n",
      "surprise\n",
      "surprise\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "joy\n",
      "fear\n",
      "surprise\n",
      "fear\n",
      "sad\n",
      "sad\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "fear\n",
      "sad\n",
      "surprise\n",
      "joy\n",
      "Classification Accuracy:  0.2\n",
      "ParseFunc = TI-IDF, K = 10, DisFunc = Dis2\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "Classification Accuracy:  0.2\n",
      "ParseFunc = TI-IDF, K = 10, DisFunc = DisInf\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "Classification Accuracy:  0.24\n",
      "ParseFunc = TI-IDF, K = 10, DisFunc = DisCosine\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "joy\n",
      "joy\n",
      "anger\n",
      "sad\n",
      "sad\n",
      "joy\n",
      "joy\n",
      "sad\n",
      "sad\n",
      "surprise\n",
      "fear\n",
      "sad\n",
      "fear\n",
      "joy\n",
      "Classification Accuracy:  0.4\n",
      "ParseFunc = TI-IDF, K = 11, DisFunc = Dis1\n",
      "surprise\n",
      "sad\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "joy\n",
      "fear\n",
      "surprise\n",
      "fear\n",
      "fear\n",
      "fear\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "fear\n",
      "sad\n",
      "fear\n",
      "joy\n",
      "Classification Accuracy:  0.28\n",
      "ParseFunc = TI-IDF, K = 11, DisFunc = Dis2\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "Classification Accuracy:  0.16\n",
      "ParseFunc = TI-IDF, K = 11, DisFunc = DisInf\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "Classification Accuracy:  0.24\n",
      "ParseFunc = TI-IDF, K = 11, DisFunc = DisCosine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy\n",
      "sad\n",
      "sad\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "joy\n",
      "joy\n",
      "anger\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "joy\n",
      "sad\n",
      "sad\n",
      "surprise\n",
      "fear\n",
      "sad\n",
      "fear\n",
      "fear\n",
      "Classification Accuracy:  0.36\n",
      "ParseFunc = TI-IDF, K = 12, DisFunc = Dis1\n",
      "surprise\n",
      "sad\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "surprise\n",
      "joy\n",
      "fear\n",
      "surprise\n",
      "fear\n",
      "fear\n",
      "fear\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "fear\n",
      "sad\n",
      "surprise\n",
      "joy\n",
      "Classification Accuracy:  0.2\n",
      "ParseFunc = TI-IDF, K = 12, DisFunc = Dis2\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "Classification Accuracy:  0.16\n",
      "ParseFunc = TI-IDF, K = 12, DisFunc = DisInf\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "sad\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "Classification Accuracy:  0.28\n",
      "ParseFunc = TI-IDF, K = 12, DisFunc = DisCosine\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "joy\n",
      "anger\n",
      "sad\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "sad\n",
      "sad\n",
      "sad\n",
      "fear\n",
      "sad\n",
      "fear\n",
      "fear\n",
      "Classification Accuracy:  0.32\n",
      "ParseFunc = TI-IDF, K = 13, DisFunc = Dis1\n",
      "surprise\n",
      "sad\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "surprise\n",
      "fear\n",
      "fear\n",
      "fear\n",
      "fear\n",
      "fear\n",
      "fear\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "fear\n",
      "joy\n",
      "fear\n",
      "joy\n",
      "Classification Accuracy:  0.24\n",
      "ParseFunc = TI-IDF, K = 13, DisFunc = Dis2\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "Classification Accuracy:  0.16\n",
      "ParseFunc = TI-IDF, K = 13, DisFunc = DisInf\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "surprise\n",
      "Classification Accuracy:  0.24\n",
      "ParseFunc = TI-IDF, K = 13, DisFunc = DisCosine\n",
      "joy\n",
      "sad\n",
      "sad\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "surprise\n",
      "joy\n",
      "joy\n",
      "anger\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "joy\n",
      "sad\n",
      "sad\n",
      "sad\n",
      "fear\n",
      "sad\n",
      "fear\n",
      "fear\n",
      "Classification Accuracy:  0.32\n",
      "48 groups of argument tested, spent 10.333461999893188s\n"
     ]
    }
   ],
   "source": [
    "train_filen = 'lab1_data/classification_dataset/train_set.csv'\n",
    "vaild_filen = 'lab1_data/classification_dataset/validation_set.csv'\n",
    "test_filen  = 'lab1_data/classification_dataset/test_set.csv'\n",
    "check_filen = 'lab1_data/classification_dataset/classification_simple_test.csv'\n",
    "\n",
    "classifyResults = autoTrain(train_filen, check_filen, classifyReadFile, classifyParseY, do_classify)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('TI-IDF', 8, 'DisCosine'), 0.3243761817506015),\n",
       " (('TI-IDF', 9, 'DisCosine'), 0.3110749022867883),\n",
       " (('TI-IDF', 11, 'DisCosine'), 0.2946464336659154),\n",
       " (('TI-IDF', 12, 'DisCosine'), 0.29215612729995527),\n",
       " (('TI-IDF', 10, 'DisCosine'), 0.2795617053186809),\n",
       " (('TI-IDF', 13, 'DisCosine'), 0.26733021096490167),\n",
       " (('TI-IDF', 10, 'Dis1'), 0.1940584122652229),\n",
       " (('TI-IDF', 13, 'Dis1'), 0.18896057300694216),\n",
       " (('TI-IDF', 9, 'Dis1'), 0.18727471353307015),\n",
       " (('TI-IDF', 11, 'Dis1'), 0.18618206208300947),\n",
       " (('TI-IDF', 8, 'Dis1'), 0.17822872901434397),\n",
       " (('TI-IDF', 12, 'Dis1'), 0.15600179278302273),\n",
       " (('OneHot', 9, 'DisCosine'), 0.14535638921816824),\n",
       " (('OneHot', 8, 'DisCosine'), 0.14422915063073075),\n",
       " (('OneHot', 11, 'DisCosine'), 0.12535041383007875),\n",
       " (('OneHot', 10, 'DisCosine'), 0.12019731582401032),\n",
       " (('OneHot', 13, 'Dis1'), 0.11728790113729382),\n",
       " (('OneHot', 12, 'DisCosine'), 0.11716670929195938),\n",
       " (('OneHot', 13, 'Dis2'), 0.11530713739396554),\n",
       " (('OneHot', 12, 'Dis1'), 0.11529531375635386),\n",
       " (('OneHot', 12, 'Dis2'), 0.11471493302581488),\n",
       " (('TI-IDF', 8, 'Dis2'), 0.10825907568634396),\n",
       " (('TI-IDF', 12, 'Dis2'), 0.080667669173477),\n",
       " (('OneHot', 13, 'DisCosine'), 0.07402992915185862),\n",
       " (('OneHot', 11, 'Dis1'), 0.07275163092217607),\n",
       " (('OneHot', 11, 'Dis2'), 0.07199644776535992),\n",
       " (('OneHot', 9, 'Dis1'), 0.068839190450758),\n",
       " (('OneHot', 9, 'Dis2'), 0.0677163614101088),\n",
       " (('TI-IDF', 10, 'DisInf'), 0.033290633972255596),\n",
       " (('TI-IDF', 11, 'Dis2'), 0.025998644054975525),\n",
       " (('TI-IDF', 10, 'Dis2'), 0.02090894677149753),\n",
       " (('OneHot', 10, 'Dis1'), 0.019761681982115507),\n",
       " (('OneHot', 10, 'Dis2'), 0.0166336329103878),\n",
       " (('TI-IDF', 12, 'DisInf'), 0.015611653900144332),\n",
       " (('TI-IDF', 13, 'Dis2'), 0.015461260253084341),\n",
       " (('OneHot', 8, 'Dis1'), 0.014621701763969847),\n",
       " (('OneHot', 8, 'Dis2'), 0.010185941572604896),\n",
       " (('TI-IDF', 9, 'Dis2'), 0.006364850321251225),\n",
       " (('OneHot', 8, 'DisInf'), nan),\n",
       " (('OneHot', 9, 'DisInf'), nan),\n",
       " (('OneHot', 10, 'DisInf'), nan),\n",
       " (('OneHot', 11, 'DisInf'), nan),\n",
       " (('OneHot', 12, 'DisInf'), nan),\n",
       " (('OneHot', 13, 'DisInf'), nan),\n",
       " (('TI-IDF', 11, 'DisInf'), -0.03772311525175214),\n",
       " (('TI-IDF', 13, 'DisInf'), -0.04355139198132124),\n",
       " (('TI-IDF', 9, 'DisInf'), -0.07022235438149386),\n",
       " (('TI-IDF', 8, 'DisInf'), -0.07193548951788842)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(regressResults.items(), key=lambda kv: 0 if np.isnan(kv[1]) else kv[1] , reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('TI-IDF', 8, 'DisCosine'), 0.4),\n",
       " (('TI-IDF', 10, 'DisCosine'), 0.4),\n",
       " (('TI-IDF', 9, 'DisCosine'), 0.36),\n",
       " (('TI-IDF', 11, 'DisCosine'), 0.36),\n",
       " (('TI-IDF', 9, 'Dis1'), 0.32),\n",
       " (('TI-IDF', 12, 'DisCosine'), 0.32),\n",
       " (('TI-IDF', 13, 'DisCosine'), 0.32),\n",
       " (('OneHot', 8, 'DisCosine'), 0.28),\n",
       " (('OneHot', 11, 'Dis1'), 0.28),\n",
       " (('OneHot', 11, 'Dis2'), 0.28),\n",
       " (('TI-IDF', 11, 'Dis1'), 0.28),\n",
       " (('TI-IDF', 12, 'DisInf'), 0.28),\n",
       " (('OneHot', 9, 'DisCosine'), 0.24),\n",
       " (('OneHot', 10, 'Dis1'), 0.24),\n",
       " (('OneHot', 10, 'Dis2'), 0.24),\n",
       " (('OneHot', 10, 'DisCosine'), 0.24),\n",
       " (('OneHot', 11, 'DisCosine'), 0.24),\n",
       " (('OneHot', 12, 'Dis1'), 0.24),\n",
       " (('OneHot', 12, 'Dis2'), 0.24),\n",
       " (('OneHot', 12, 'DisCosine'), 0.24),\n",
       " (('OneHot', 13, 'Dis1'), 0.24),\n",
       " (('OneHot', 13, 'Dis2'), 0.24),\n",
       " (('OneHot', 13, 'DisCosine'), 0.24),\n",
       " (('TI-IDF', 8, 'Dis1'), 0.24),\n",
       " (('TI-IDF', 8, 'Dis2'), 0.24),\n",
       " (('TI-IDF', 8, 'DisInf'), 0.24),\n",
       " (('TI-IDF', 9, 'DisInf'), 0.24),\n",
       " (('TI-IDF', 10, 'DisInf'), 0.24),\n",
       " (('TI-IDF', 11, 'DisInf'), 0.24),\n",
       " (('TI-IDF', 13, 'Dis1'), 0.24),\n",
       " (('TI-IDF', 13, 'DisInf'), 0.24),\n",
       " (('OneHot', 8, 'Dis1'), 0.2),\n",
       " (('OneHot', 8, 'Dis2'), 0.2),\n",
       " (('OneHot', 8, 'DisInf'), 0.2),\n",
       " (('OneHot', 9, 'Dis1'), 0.2),\n",
       " (('OneHot', 9, 'Dis2'), 0.2),\n",
       " (('OneHot', 9, 'DisInf'), 0.2),\n",
       " (('OneHot', 10, 'DisInf'), 0.2),\n",
       " (('OneHot', 11, 'DisInf'), 0.2),\n",
       " (('OneHot', 12, 'DisInf'), 0.2),\n",
       " (('OneHot', 13, 'DisInf'), 0.2),\n",
       " (('TI-IDF', 9, 'Dis2'), 0.2),\n",
       " (('TI-IDF', 10, 'Dis1'), 0.2),\n",
       " (('TI-IDF', 10, 'Dis2'), 0.2),\n",
       " (('TI-IDF', 12, 'Dis1'), 0.2),\n",
       " (('TI-IDF', 11, 'Dis2'), 0.16),\n",
       " (('TI-IDF', 12, 'Dis2'), 0.16),\n",
       " (('TI-IDF', 13, 'Dis2'), 0.16)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(classifyResults.items(), key=lambda kv: kv[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy\n",
      "sad\n",
      "joy\n",
      "fear\n",
      "fear\n",
      "joy\n",
      "sad\n",
      "joy\n",
      "surprise\n",
      "joy\n",
      "surprise\n",
      "joy\n",
      "joy\n",
      "anger\n",
      "sad\n",
      "sad\n",
      "joy\n",
      "joy\n",
      "sad\n",
      "sad\n",
      "surprise\n",
      "fear\n",
      "sad\n",
      "fear\n",
      "joy\n",
      "Classification Accuracy:  0.4\n"
     ]
    }
   ],
   "source": [
    "train_filen = 'lab1_data/classification_dataset/train_set.csv'\n",
    "vaild_filen = 'lab1_data/classification_dataset/validation_set.csv'\n",
    "test_filen  = 'lab1_data/classification_dataset/test_set.csv'\n",
    "check_filen = 'lab1_data/classification_dataset/classification_simple_test.csv'\n",
    "\n",
    "ReadFileFunc = classifyReadFile\n",
    "ParseYFunc = classifyParseY\n",
    "TrainFunc = do_classify\n",
    "\n",
    "ParseFunc = KNN_getTFIDF\n",
    "DisFunc = DisCosine\n",
    "K = 10\n",
    "\n",
    "trainX_data, trainY_data = ReadFileFunc(train_filen)\n",
    "vaildX_data, vaildY_data = ReadFileFunc(check_filen)\n",
    "word_dict = OrderedDict()\n",
    "def ParseXFunc(fdata: List[List]): return ParseFunc(fdata, word_dict)\n",
    "trainX, trainY = vectorizeData(trainX_data, trainY_data, ParseXFunc, ParseYFunc)\n",
    "vaildX, vaildY = vectorizeData(vaildX_data, vaildY_data, ParseXFunc, ParseYFunc)\n",
    "def knnFunc(trainX, trainY, vaildX): return KNN((trainX, trainY), vaildX, DisFunc, K, DisInvNormAvg)\n",
    "ret = TrainFunc(trainX, trainY, vaildX, vaildY, knnFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Coefficient:  0.3243761817506015\n"
     ]
    }
   ],
   "source": [
    "train_filen = 'lab1_data/regression_dataset/train_set.csv'\n",
    "vaild_filen = 'lab1_data/regression_dataset/validation_set.csv'\n",
    "test_filen  = 'lab1_data/regression_dataset/test_set.csv'\n",
    "check_filen = 'lab1_data/regression_dataset/regression_simple_test.csv'\n",
    "\n",
    "ReadFileFunc = regressReadFile\n",
    "ParseYFunc = regressParseY\n",
    "TrainFunc = do_regress\n",
    "\n",
    "ParseFunc = KNN_getTFIDF\n",
    "DisFunc = DisCosine\n",
    "K = 8\n",
    "\n",
    "trainX_data, trainY_data = ReadFileFunc(train_filen)\n",
    "vaildX_data, vaildY_data = ReadFileFunc(check_filen)\n",
    "word_dict = OrderedDict()\n",
    "def ParseXFunc(fdata: List[List]): return ParseFunc(fdata, word_dict)\n",
    "trainX, trainY = vectorizeData(trainX_data, trainY_data, ParseXFunc, ParseYFunc)\n",
    "vaildX, vaildY = vectorizeData(vaildX_data, vaildY_data, ParseXFunc, ParseYFunc)\n",
    "def knnFunc(trainX, trainY, vaildX): return KNN((trainX, trainY), vaildX, DisFunc, K, DisInvNormAvg)\n",
    "ret = TrainFunc(trainX, trainY, vaildX, vaildY, knnFunc, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
