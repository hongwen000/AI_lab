# 中山大学数据科学与计算机学院

# 计算机科学与技术专业-人工智能

# 本科生实验报告

# (2018-2019学年秋季学期)

课程名称：  **Artificial Intelligence** 

| 教学班级 | 计科2班  | 专业（方向） | 计算机科学与技术 |
| -------- | -------- | ------------ | ---------------- |
| 学号     | 15323032 | 姓名         | 李新锐           |

## 实验题目

⽂本数据集简单处理 &KNN 

## 实验内容

### 一、算法原理

本实验中，我们学习了基于TF-IDF算法的文本数据集处理及KNN算法的原理与实现。

TF-IDF算法的输入是一个文章集合，每篇文章由单词组成，因此可视为一个二维矩阵。输出是文章集合中每一个单词的重要程度的一维向量。

该算法基于一个对单词重要程度的假设：越重要的单词应当在某篇文章中出现次数很多，但在文章集中出现的频率却是较低的。举例而言，我们现在假如以一部人工智能算法论文集作为训练集合，要求求出每个单词的重要性。在一篇有关KNN算法的论文中，“KNN”一词可能反复出现，同时在其他论文中可能几乎不出现。因此被看作有很高的重要性。反之，单词“to”在一篇文章中虽然出现次数很多，但由于它几乎是在每篇文章中出现，因此给予TF-IDF算法，其重要性几乎为0。可见，该算法是较为符合实际情况的。

KNN算法的是一种监督学习方法，它的基本原理是：对于要预测的**输入X**，他依据给定的**距离测度**，在训练集中找到**最临近的K个**向量，将这K个向量的Y依据距离进行**加权**，作为最终预测的输出。

直观地，我们可以理解KNN是一种“找原题”算法，他仅仅是从已知的数据集中寻找最相似的，把它们的答案加权综合起来作为新题的答案，而不进行其他的规律总结。

## 二、伪代码



## 三、关键代码截图（带注释）



## 四、创新点&优化

1. 在处理TF-IDF矩阵时引入了特殊的nan单词，代表训练集中没有而出现在预测集中的单词。